export build_tarballs, autobuild, print_artifacts_toml, build
import GitHub: gh_get_json, DEFAULT_API
import SHA: sha256, sha1
using Pkg.TOML, Dates, UUIDs
using RegistryTools, Registrator, JLLTools
import LibGit2
import PkgLicenses

const BUILD_HELP = (
    """
    Usage: build_tarballs.jl [target1,target2,...] [--help]
                             [--verbose] [--debug]
                             [--deploy] [--deploy-bin] [--deploy-jll]
                             [--register] [--meta-json]

    Options:
        targets             By default `build_tarballs.jl` will build a tarball
                            for every target within the `platforms` variable.
                            To override this, pass in a list of comma-separated
                            target triplets for each target to be built.  Note
                            that this can be used to build for platforms that
                            are not listed in the 'default list' of platforms
                            in the build_tarballs.jl script.

        --verbose           This streams compiler output to stdout during the
                            build which can be very helpful for finding bugs.
                            Note that it is colorized if you pass the
                            --color=yes option to julia, see examples below.

        --debug             This causes a failed build to drop into an
                            interactive shell for debugging purposes.

        --deploy=<repo>     Deploy binaries and JLL wrapper code to a github
                            release of an autogenerated repository.  Uses
                            `github.com/JuliaBinaryWrappers/<name>_jll.jl` by
                            default, unless `<repo>` is set, in which case it
                            should be set as `<owner>/<name>_jll.jl`.  Setting
                            this option is equivalent to setting `--deploy-bin`
                            and `--deploy-jll`.

        --deploy-bin=<repo> Deploy just the built binaries

        --deploy-jll=<repo> Deploy just the JLL code wrappers

        --register=<depot>  Register into the given depot.  If no path is
                            given, defaults to `~/.julia`.  Registration
                            requires deployment of the JLL wrapper code, so
                            so using `--register` without `--deploy` or the
                            more specific `--deploy-jll` is an error.

        --meta-json         Output a JSON representation of the given build
                            instead of actually building.  Note that this can
                            (and often does) output multiple JSON objects for
                            multiple platforms, multi-stage builds, etc...

        --help              Print out this message.

    Examples:
        julia --color=yes build_tarballs.jl --verbose
            This builds all tarballs, with colorized output.

        julia build_tarballs.jl x86_64-linux-gnu,i686-linux-gnu
            This builds two tarballs for the two platforms given, with a
            minimum of output messages.
    """
)

"""
    build_tarballs(ARGS, src_name, src_version, sources, script, platforms,
                   products, dependencies; kwargs...)

This should be the top-level function called from a `build_tarballs.jl` file.
It takes in the information baked into a `build_tarballs.jl` file such as the
`sources` to download, the `products` to build, etc... and will automatically
download, build and package the tarballs, generating a `build.jl` file when
appropriate.  Note that `ARGS` should be the top-level Julia `ARGS` command-
line arguments object.  This function does some rudimentary parsing of the
`ARGS`, call it with `--help` in the `ARGS` to see what it can do.

The `kwargs` are passed on to [`autobuild`](@ref), see there for a list of
supported ones. In addition, the keyword argument `init_block` may be set to
a string containing Julia code; if present, this code will be inserted into
the initialization path of the generated JLL package. This can for example be
used to invoke an initialization API of a shared library.

!!! note

    The `init_block` keyword argument is experimental and may be removed
    in a future version of this package. Please use it sparingly.
"""
function build_tarballs(ARGS, src_name, src_version, sources, script,
                        platforms, products, dependencies; kwargs...)
    @nospecialize
    # See if someone has passed in `--help`, and if so, give them the
    # assistance they so clearly long for
    if "--help" in ARGS
        println(BUILD_HELP)
        return nothing
    end

    # XXX: These are needed as long as we support old-style sources and
    # dependencies.  Raise a warning for now, deprecate in BB 0.3+
    sources = coerce_source.(sources)
    dependencies = coerce_dependency.(dependencies)

    # Do not clobber caller's ARGS
    ARGS = deepcopy(ARGS)

    # This sets whether we should build verbosely or not
    verbose = check_flag!(ARGS, "--verbose")

    # This sets whether we drop into a debug shell on failure or not
    debug = check_flag!(ARGS, "--debug")

    # Are we skipping building and just outputting JSON?
    meta_json, meta_json_file = extract_flag!(ARGS, "--meta-json")

    # This sets whether we are going to deploy our binaries/wrapper code to GitHub releases
    deploy, deploy_repo = extract_flag!(ARGS, "--deploy", "JuliaBinaryWrappers/$(src_name)_jll.jl")
    deploy_bin, deploy_bin_repo = extract_flag!(ARGS, "--deploy-bin", "JuliaBinaryWrappers/$(src_name)_jll.jl")
    deploy_jll, deploy_jll_repo = extract_flag!(ARGS, "--deploy-jll", "JuliaBinaryWrappers/$(src_name)_jll.jl")

    # Resolve deploy settings
    if deploy
        deploy_bin = true
        deploy_jll = true
        deploy_bin_repo = deploy_repo
        deploy_jll_repo = deploy_repo
    elseif deploy_bin # make sure bin repo and jll repo match
        deploy_jll_repo = deploy_bin_repo 
    elseif deploy_jll 
        deploy_bin_repo = deploy_jll_repo
    elseif deploy_bin && deploy_jll
        if deploy_bin_repo != deploy_jll_repo
            error("Binaries and JLLs must be deployed to the same repositories")
        end
    end

    # This sets whether we are going to register, and if so, which
    register, register_path = extract_flag!(ARGS, "--register", Pkg.depots1())
    if register && !deploy_jll
        error("Cannot register without deploying!")
    end

    if deploy_bin || deploy_jll
        code_dir = joinpath(Pkg.devdir(), "$(src_name)_jll")

        # Shove them into `kwargs` so that we are conditionally passing them along
        kwargs = (; kwargs..., code_dir = code_dir)
    end

    # If --meta-json was passed, error out if any confusing options were passed
    meta_json_stream = nothing
    if meta_json
        if deploy || deploy_bin || deploy_jll
            error("Cannot specify --deploy* with --meta-json!")
        end
        if register
            error("Cannot specify --register with --meta-json!")
        end
        if debug
            error("Cannot specify --debug with --meta-json!")
        end

        # Otherwise, check to see if we're spitting it out to stdout or a file:
        if meta_json_file === nothing
            meta_json_stream = stdout
        else
            meta_json_stream = open(meta_json_file, "a")
        end
    end

    # If the user passed in a platform (or a few, comma-separated) on the
    # command-line, use that instead of our default platforms
    if length(ARGS) > 0
        _platform_key_abi(p::AbstractString) = p == "any" ? AnyPlatform() : platform_key_abi(p)
        platforms = _platform_key_abi.(split(ARGS[1], ","))
    end

    # Check to make sure we have the necessary environment stuff
    if deploy_bin || deploy_jll
        # Check to see if we've already got a wrapper package within the Registry,
        # choose a version number that is greater than anything else existent.
        build_version = get_next_wrapper_version(src_name, src_version)
        if verbose
            @info("Building and deploying version $(build_version) to $(deploy_repo)")
        end
        tag = "$(src_name)-v$(build_version)"

        # We need to make sure that the JLL repo at least exists, so that we can deploy binaries to it
        # even if we're not planning to register things to it today.
        init_jll_package(src_name, code_dir, deploy_jll_repo)
    end

    # Build the given platforms using the given sources
    build_output_meta = autobuild(
        # Controls output product placement, mount directory placement, etc...
        pwd(),

        # Source information
        src_name,
        src_version,
        sources,

        # Build script
        script,

        # Platforms to build for
        platforms,

        # Products we're expecting
        products,

        # Dependencies that must be downloaded
        dependencies;

        # Flags
        verbose=verbose,
        debug=debug,
        meta_json_stream=meta_json_stream,
        kwargs...,
    )

    if meta_json_stream !== nothing && meta_json_stream !== stdout
        close(meta_json_stream)
    end

    if deploy_jll
        if verbose
            @info("Building $(src_name)_jll.jl wrapper code version $(build_version)...")
        end

        # For deploy discard build-only dependencies
        # and make sure we get a `Vector{Dependency}`
        dependencies = Dependency[dep for dep in dependencies if !isa(dep, BuildDependency)]

        # The location the binaries will be available from
        bin_path = "https://github.com/$(deploy_jll_repo)/releases/download/$(tag)"
        build_jll_package(
            src_name,
            build_version,
            sources,
            code_dir,
            build_output_meta,
            dependencies,
            bin_path;
            verbose=verbose,
            extract_kwargs(kwargs, (:lazy_artifacts, :init_block))...,
        )

        if deploy_repo != "local"
            if verbose
                @info("Pushing to $(deploy_repo)...")
            end

            push_jll_package(src_name, build_version; code_dir=code_dir, deploy_repo=deploy_repo)
            if register
                if verbose
                    @info("Registering $(deploy_repo) version $(build_version)...")
                end

                register_jll(src_name, build_version, dependencies;
                                deploy_repo=deploy_jll_repo, code_dir=code_dir)
            end
        end
    end

    if deploy_bin
        # Upload the binaries
        if verbose
            @info("Deploying binaries to release $(tag) on $(deploy_bin_repo) via `ghr`...")
        end
        upload_to_github_releases(deploy_bin_repo, tag, joinpath(pwd(), "products"); verbose=verbose)
    end

    return build_output_meta
end

function check_flag!(ARGS, flag)
    flag_present = flag in ARGS
    filter!(x -> x != flag, ARGS)
    return flag_present
end

function extract_flag!(ARGS, flag, val = nothing)
    for f in ARGS
        if f == flag || startswith(f, string(flag, "="))
            # Check if it's just `--flag` or if it's `--flag=foo`
            if f != flag
                val = split(f, '=')[2]
            end

            # Drop this value from our ARGS
            filter!(x -> x != f, ARGS)
            return (true, val)
        end
    end
    return (false, val)
end

"""
    get_compilers_versions(; compilers = [:c])

Return the script string that is used to print the versions of the given `compilers`.
"""
function get_compilers_versions(; compilers = [:c])
    output =
        """
        set -x
        """
    if :c in compilers
        output *=
            """
            cc --version
            c++ --version
            gcc --version
            g++ --version
            clang --version
            clang++ --version
            objc --version
            f77 --version
            gfortran --version
            ld -v
            """
    end
    if :go in compilers
        output *=
            """
            go version
            """
    end
    if :rust in compilers
        output *=
            """
            rustc --version
            rustup --version
            cargo --version
            """
    end
    return output
end

function upload_to_github_releases(repo, tag, path; gh_auth=Wizard.github_auth(;allow_anonymous=false), 
                                   attempts::Int = 3, verbose::Bool = false)
    for attempt in 1:attempts
        try
            ghr() do ghr_path
                run(`$ghr_path -u $(dirname(repo)) -r $(basename(repo)) -t $(gh_auth.token) $(tag) $(path)`)
            end
            return
        catch
            if verbose
                @info("`ghr` upload step failed, beginning attempt #$(attempt)...")
            end
        end
    end
    error("Unable to upload $(path) to GitHub repo $(repo) on tag $(tag)")
end

"""
    autobuild(dir::AbstractString, src_name::AbstractString,
              src_version::VersionNumber, sources::Vector,
              script::AbstractString, platforms::Vector,
              products::Vector, dependencies::Vector;
              verbose = false, debug = false,
              skip_audit = false, ignore_audit_errors = true,
              autofix = true, code_dir = nothing,
              meta_json_file = nothing, require_license = true, kwargs...)

Runs the boiler plate code to download, build, and package a source package
for a list of platforms.  This method takes a veritable truckload of arguments,
here are the relevant actors, broken down in brief:

* `dir`: the root of the build; products will be placed within `dir`/products,
   and mountpoints will be placed within `dir`/build/.

* `src_name`: the name of the source package being built and will set the name
   of the built tarballs.

* `src_version`: the version of the source package.

* `platforms`: a list of platforms to build for.

* `sources`: a vector of all sources to download and unpack before building
  begins, as [`AbstractSource`](@ref)s.

* `script`: a string representing a shell script to run as the build.

* `products`: the list of `Product`s which shall be built.

* `dependencies`: a vector of JLL dependency packages as
  [`AbstractDependency`](@ref) that should be installed before building begins.

* `verbose`: Enable verbose mode.  What did you expect?

* `debug`: cause a failed build to drop into an interactive shell so that
   the build can be inspected easily.

* `skip_audit`: disable the typical audit that occurs at the end of a build.

* `ignore_audit_errors`: do not kill a build even if a problem is found.

* `autofix`: give `BinaryBuilder` permission to automatically fix issues it
   finds during audit passes.  Highly recommended.

* `code_dir`: sets where autogenerated JLL packages will be put.

* `require_license` enables a special audit pass that requires licenses to be
   installed by all packages.

* `lazy_artifacts` sets whether the artifacts should be lazy.

* `meta_json_stream`: If this is set to an IOStream, do not actually build, just
   output a JSON representation of all the metadata about this build to the stream.
"""
function autobuild(dir::AbstractString,
                   src_name::AbstractString,
                   src_version::VersionNumber,
                   sources::Vector{<:AbstractSource},
                   script::AbstractString,
                   platforms::Vector,
                   products::Vector{<:Product},
                   dependencies::Vector{<:AbstractDependency};
                   verbose::Bool = false,
                   debug::Bool = false,
                   skip_audit::Bool = false,
                   ignore_audit_errors::Bool = true,
                   autofix::Bool = true,
                   code_dir::Union{String,Nothing} = nothing,
                   require_license::Bool = true,
                   lazy_artifacts::Bool = false,
                   init_block::String = "",
                   meta_json_stream = nothing,
                   kwargs...)
    @nospecialize
    # If they've asked for the JSON metadata, by all means, give it to them!
    if meta_json_stream !== nothing
        dict = Dict(
            "name" => src_name,
            "version" => "v$(src_version)",
            "sources" => sources,
            "script" => script,
            "products" => products,
            "dependencies" => dependencies,
            "lazy_artifacts" => lazy_artifacts,
            "init_block" => init_block,
        )
        # Do not write the list of platforms when building only for `AnyPlatform`
        if platforms != [AnyPlatform()]
            dict["platforms"] = triplet.(platforms)
        end
        println(meta_json_stream, JSON.json(dict))
        return Dict()
    end

    # If we're on CI and we're not verbose, schedule a task to output a "." every few seconds
    if (haskey(ENV, "TRAVIS") || haskey(ENV, "CI")) && !verbose
        run_travis_busytask = true
        travis_busytask = @async begin
            # Don't let Travis think we're asleep...
            @info("Brewing a pot of coffee for Travis...")
            while run_travis_busytask
                sleep(4)
                print(".")
            end
        end
    end

    # This is what we'll eventually return
    @info("Building for $(join(triplet.(platforms), ", "))")
    build_output_meta = Dict()

    # Resolve dependencies into PackageSpecs now, ensuring we have UUIDs for all deps
    all_resolved, dependencies = resolve_jlls(dependencies)
    if !all_resolved
        error("Invalid dependency specifications!")
    end

    # If the user passed in a src_version with a build number, bail out
    if src_version.build != ()
        error("Will not build with a `src_version` that has a build number already specified!")
    end

    # We must prepare our sources.  Download them, hash them, etc...
    source_files = download_source.(sources; verbose=verbose)

    # Our build products will go into ./products
    out_path = joinpath(dir, "products")
    try mkpath(out_path) catch; end

    for platform in sort(collect(platforms), by = triplet)
        # We build in a platform-specific directory
        build_path = joinpath(dir, "build", triplet(platform))
        mkpath(build_path)

        shards = choose_shards(platform; extract_kwargs(kwargs, (:preferred_gcc_version,:preferred_llvm_version,:bootstrap_list,:compilers))...)
        concrete_platform = get_concrete_platform(platform, shards)

        prefix = setup_workspace(
            build_path,
            source_files;
            verbose=verbose,
        )
        artifact_paths = setup_dependencies(prefix, getpkg.(dependencies), concrete_platform)

        # Create a runner to work inside this workspace with the nonce built-in
        ur = preferred_runner()(
            prefix.path;
            cwd = "/workspace/srcdir",
            platform = concrete_platform,
            verbose = verbose,
            workspaces = [
                joinpath(prefix, "metadir") => "/meta",
            ],
            compiler_wrapper_dir = joinpath(prefix, "compiler_wrappers"),
            src_name = src_name,
            shards = shards,
            extract_kwargs(kwargs, (:preferred_gcc_version,:preferred_llvm_version,:compilers,:allow_unsafe_flags,:lock_microarchitecture))...,
        )

        # Set up some bash traps
        trapper_wrapper = """
        # Stop if we hit any errors.
        set -e

        # If we're running as `bash`, then use the `DEBUG` and `ERR` traps
        if [ \$(basename \$0) = "bash" ]; then
            trap "RET=\\\$?; \\
                  trap - DEBUG INT TERM ERR EXIT; \\
                  set +e +x; \\
                  auto_install_license; \\
                  save_env; \\
                  exit \\\$RET" \\
                EXIT

            trap "RET=\\\$?; \\
                  trap - DEBUG INT TERM ERR EXIT; \\
                  set +e +x; \\
                  echo Previous command \\\$! exited with \\\$RET >&2; \\
                  save_env; \\
                  exit \\\$RET" \\
                INT TERM ERR

            # Start saving everything into our history
            trap save_history DEBUG
        else
            # If we're running in `sh` or something like that, we need a
            # slightly slimmer set of traps. :(
            trap "RET=\\\$?; \\
                  echo Previous command exited with \\\$RET >&2; \\
                  set +e +x; \\
                  save_env; \\
                  exit \\\$RET" \\
                EXIT INT TERM
        fi

        $(script)
        """

        dest_prefix = Prefix(joinpath(prefix.path, "destdir"))
        did_succeed = with_logfile(dest_prefix, "$(src_name).log") do io
            # Let's start the presentations with BinaryBuilder.jl
            write(io, "BinaryBuilder.jl version: $(get_bb_version())\n\n")
            # Get the list of compilers...
            compilers = extract_kwargs(kwargs, (:compilers,))
            # ...because we want to log all their versions.  However, we don't
            # want this to be shown in the console, so we first run this without
            # teeing to stdout
            run(ur, `/bin/bash -l -c $(get_compilers_versions(; compilers...))`, io;
                verbose = verbose, tee_stream = devnull)
            # Run the build script
            run(ur, `/bin/bash -l -c $(trapper_wrapper)`, io; verbose=verbose)
        end
        if !did_succeed
            if debug
                @warn("Build failed, launching debug shell")
                run_interactive(ur, `/bin/bash -l -i`)
            end
            msg = "Build for $(src_name) on $(triplet(platform)) did not complete successfully\n"
            error(msg)
        end

        # Run an audit of the prefix to ensure it is properly relocatable
        if !skip_audit
            audit_result = audit(dest_prefix, src_name;
                                 platform=platform, verbose=verbose,
                                 has_csl = any(getname.(dependencies) .== "CompilerSupportLibraries_jll"),
                                 autofix=autofix, require_license=require_license)
            if !audit_result && !ignore_audit_errors
                msg = replace("""
                Audit failed for $(dest_prefix.path).
                Address the errors above to ensure relocatability.
                To override this check, set `ignore_audit_errors = true`.
                """, '\n' => ' ')
                error(strip(msg))
            end
        end

        # Finally, error out if something isn't satisfied
        unsatisfied_so_die = false
        for p in products
            if platform isa AnyPlatform && !(p isa FileProduct)
                # `AnyPlatform` is by design platform-independent, so we allow
                # only `FileProduct`s.
                error("Cannot have $(typeof(p)) for AnyPlatform")
            end
            if !satisfied(p, dest_prefix; verbose=verbose, platform=platform)
                if !verbose
                    # If we never got a chance to see the verbose output, give it here:
                    locate(p, dest_prefix; verbose=true, platform=platform)
                end
                @error("Built $(src_name) but $(variable_name(p)) still unsatisfied:")
                unsatisfied_so_die = true
            end
        end
        if unsatisfied_so_die
            error("Cannot continue with unsatisfied build products!")
        end

        # We also need to capture some info about each product
        products_info = Dict{Product,Any}()
        for p in products
            product_path = locate(p, dest_prefix; platform=platform)
            products_info[p] = Dict("path" => relpath(product_path, dest_prefix.path))
            if p isa LibraryProduct || p isa FrameworkProduct
                products_info[p]["soname"] = something(
                    Auditor.get_soname(product_path),
                    basename(product_path),
                )
            end
        end

        # Unsymlink all the deps from the dest_prefix
        cleanup_dependencies(prefix, artifact_paths)

        # Search for dead links in dest_prefix; raise warnings about them.
        Auditor.warn_deadlinks(dest_prefix.path)

        # Cull empty directories, for neatness' sake, unless auditing is disabled
        if !skip_audit
            for (root, dirs, files) = walkdir(dest_prefix.path; topdown=false)
                # We do readdir() here because `walkdir()` does not do a true in-order traversal
                if isempty(readdir(root))
                    rm(root)
                end
            end
        end

        # Compress log files
        compress_dir(joinpath(dest_prefix.path, "logs"), verbose=verbose)

        # Once we're built up, go ahead and package this dest_prefix out
        tarball_path, tarball_hash, git_hash = package(
            dest_prefix,
            joinpath(out_path, src_name),
            src_version;
            platform=platform,
            verbose=verbose,
            force=true,
        )

        build_output_meta[platform] = (
            tarball_path,
            tarball_hash,
            git_hash,
            products_info,
        )

        # Destroy the workspace, taking care to make sure that we don't run into any
        # permissions errors while we do so.
        prepare_for_deletion(prefix.path)
        rm(prefix.path; recursive=true)

        # If the whole build_path is empty, then remove it too.  If it's not, it's probably
        # because some other build is doing something simultaneously with this target, and we
        # don't want to mess with their stuff.
        if isempty(readdir(build_path))
            rm(build_path; recursive=true)
        end
    end

    if (haskey(ENV, "TRAVIS") || haskey(ENV, "CI")) && !verbose
        run_travis_busytask = false
        wait(travis_busytask)
        println()
    end

    # Return our product hashes
    return build_output_meta
end

function prepare_for_deletion(prefix::String)
    # Temporarily work around walkdir bug with endless symlinks: https://github.com/JuliaLang/julia/pull/35006
    try
        for (root, dirs, files) in walkdir(prefix; follow_symlinks=false)
            for d in dirs
                # Ensure that each directory is writable by by the owning user (should be us)
                path = joinpath(root, d)
                try
                    chmod(path, stat(path).mode | Base.Filesystem.S_IWUSR)
                catch
                end
            end
        end
    catch
    end
end



function download_github_release(download_dir, repo, tag; gh_auth=Wizard.github_auth(), verbose::Bool=false)
    release = gh_get_json(DEFAULT_API, "/repos/$(repo)/releases/tags/$(tag)", auth=gh_auth)
    assets = [a for a in release["assets"] if endswith(a["name"], ".tar.gz")]

    for asset in assets
        if verbose
            @info("Downloading $(asset["name"])")
        end
        download(asset["browser_download_url"], joinpath(download_dir, asset["name"]))
    end
    return assets
end

## TODO: I would love to remove all these jll-related methods from here,
# but since they rely on our ability to talk to GitHub, there's not an easy
# way to split them out from BinaryBuilder into, for instance, JLLTools.
#
# Perhaps we should move the GitHub pieces over as well?
function init_jll_package(name, code_dir, deploy_repo;
                          gh_auth = Wizard.github_auth(;allow_anonymous=false),
                          gh_username = gh_get_json(DEFAULT_API, "/user"; auth=gh_auth)["login"])
    try
        # This throws if it does not exist
        GitHub.repo(deploy_repo; auth=gh_auth)
    catch e
        # If it doesn't exist, create it.
        # check whether gh_org might be a user, not an organization.
        gh_org = dirname(deploy_repo)
        isorg = GitHub.owner(gh_org; auth=gh_auth).typ == "Organization"
        owner = GitHub.Owner(gh_org, isorg)
        @info("Creating new wrapper code repo at https://github.com/$(deploy_repo)")
        try
            GitHub.create_repo(owner, basename(deploy_repo), Dict("license_template" => "mit", "has_issues" => "false"); auth=gh_auth)
        catch create_e
            # If creation failed, it could be because the repo was created in the meantime.
            # Check for that; if it still doesn't exist, then freak out.  Otherwise, continue on.
            try
                GitHub.repo(deploy_repo; auth=gh_auth)
            catch
                rethrow(create_e)
            end
        end
    end

    if !isdir(code_dir)
        # If it does exist, clone it down:
        @info("Cloning wrapper code repo from https://github.com/$(deploy_repo) into $(code_dir)")
        creds = LibGit2.UserPasswordCredential(
            deepcopy(gh_username),
            deepcopy(gh_auth.token),
        )
        try
            LibGit2.clone("https://github.com/$(deploy_repo)", code_dir; credentials=creds)
        finally
            Base.shred!(creds)
        end
    else
        # Otherwise, hard-reset to latest master:
        repo = LibGit2.GitRepo(code_dir)
        LibGit2.fetch(repo)
        origin_master_oid = LibGit2.GitHash(LibGit2.lookup_branch(repo, "origin/master", true))
        LibGit2.reset!(repo, origin_master_oid, LibGit2.Consts.RESET_HARD)
        if string(LibGit2.head_oid(repo)) != string(origin_master_oid)
            LibGit2.branch!(repo, "master", string(origin_master_oid); force=true)
        end
    end
end


# Note that rebuild_jll_package is not called from anywhere in BinaryBuilder,
# but rather from JuliaPackaging/Yggdrasil/.ci/register_package.jl
function rebuild_jll_package(obj::Dict;
                             download_dir = nothing,
                             upload_prefix = nothing,
                             build_version = nothing,
                             gh_org::String = "JuliaBinaryWrappers",
                             verbose::Bool = false,
                             lazy_artifacts::Bool = false,
                             from_scratch::Bool = true)
    if build_version === nothing
        build_version = BinaryBuilder.get_next_wrapper_version(obj["name"], obj["version"])
    end
    if download_dir === nothing
        download_dir = mktempdir()
        repo = "$(gh_org)/$(name)_jll.jl"
        tag = "$(name)-v$(build_version)"
        download_github_release(download_dir, repo, tag; verbose=verbose)
        upload_prefix = "https://github.com/$(repo)/releases/download/$(tag)"
    elseif upload_prefix === nothing
        error("If download_dir is specified, you must specify upload_prefix as well!")
    end

    return rebuild_jll_package(
        obj["name"],
        build_version,
        obj["sources"],
        obj["platforms"],
        obj["products"],
        obj["dependencies"],
        download_dir,
        upload_prefix;
        verbose=verbose,
        lazy_artifacts = lazy_artifacts,
        init_block = get(obj, "init_block", ""),
        from_scratch = from_scratch,
    )
end

"""
    registered_packages(registry_url::String)

Returns a list of all packages registered within the given registry after updating it.
"""
function registered_packages(registry_url::AbstractString)
    # Update registry
    ctx = Pkg.Types.Context()
    reg = RegistrySpec(name=basename(registry_url), url=registry_url)
    Pkg.Registry.update(reg)
    reg = first(Pkg.Types.find_installed_registries(ctx, [reg]))

    registry = TOML.parsefile(joinpath(reg.path, "Registry.toml"))
    packages = Vector{String}(undef, 0)
    for p in registry["packages"]
        push!(packages, p[2]["name"])
    end
    return packages
end

"""
    package_is_registered(registry_url::String, package::String)

Given a registry url and a package name, return true if such a package exists within the
given reigstry.  Has the side-effect of updating the local registry, if it exists.
"""
function package_is_registered(registry_url::AbstractString,
                               package::AbstractString)
    registered_packages = registered_packages(registry_url)
    return package in registered_packages
end

function register_jll(name, build_version, dependencies;
                      deploy_repo="JuliaBinaryWrappers/$(name)_jll.jl",
                      code_dir=joinpath(Pkg.devdir(), "$(name)_jll"),
                      gh_auth=Wizard.github_auth(;allow_anonymous=false),
                      gh_username=gh_get_json(DEFAULT_API, "/user"; auth=gh_auth)["login"])
    if !Base.isidentifier(name)
        error("Package name \"$(name)\" is not a valid identifier")
    end
    # Calculate tree hash of wrapper code
    wrapper_tree_hash = bytes2hex(Pkg.GitTools.tree_hash(code_dir))

    # Use RegistryTools to push up a new `General` branch with this JLL package registered within it
    # TODO: Update our fork periodically from upstream `General`.
    cache = RegistryTools.RegistryCache(joinpath(Pkg.depots1(), "registries_binarybuilder"))
    registry_url = "https://$(gh_username):$(gh_auth.token)@github.com/JuliaRegistries/General"
    cache.registries[registry_url] = Base.UUID("23338594-aafe-5451-b93e-139f81909106")
    project = Pkg.Types.Project(build_project_dict(name, build_version, dependencies))
    errors = setdiff(RegistryTools.registrator_errors, [:version_less_than_all_existing])
    reg_branch = RegistryTools.register(
        "https://github.com/$(deploy_repo).git",
        project,
        wrapper_tree_hash;
        registry=registry_url,
        cache=cache,
        push=true,
        checks_triggering_error = errors,
    )
    if haskey(reg_branch.metadata, "error")
        @error(reg_branch.metadata["error"])
    else
        upstream_registry_url = "https://github.com/JuliaRegistries/General"
        name_jll = "$(name)_jll"
        if package_is_registered(upstream_registry_url, name_jll)
            pr_title = "New version: $(name_jll) v$(build_version)"
        else
            pr_title = "New package: $(name_jll) v$(build_version)"
        end
        # Open pull request against JuliaRegistries/General
        params = Dict(
            "base" => "master",
            "head" => "$(reg_branch.branch)",
            "maintainer_can_modify" => true,
            "title" => pr_title,
            "body" => """
            Autogenerated JLL package registration

            * Registering JLL package $(basename(deploy_repo))
            * Repository: https://github.com/$(deploy_repo)
            * Version: v$(build_version)
            """
        )
        create_or_update_pull_request("JuliaRegistries/General", params; auth=gh_auth)
    end
end

function push_jll_package(name, build_version;
                          code_dir = joinpath(Pkg.devdir(), "$(name)_jll"),
                          deploy_repo = "JuliaBinaryWrappers/$(name)_jll.jl",
                          gh_auth = Wizard.github_auth(;allow_anonymous=false),
                          gh_username = gh_get_json(DEFAULT_API, "/user"; auth=gh_auth)["login"])
    # Next, push up the wrapper code repository
    wrapper_repo = LibGit2.GitRepo(code_dir)
    LibGit2.add!(wrapper_repo, ".")
    LibGit2.commit(wrapper_repo, "$(name)_jll build $(build_version)")
    creds = LibGit2.UserPasswordCredential(
        deepcopy(gh_username),
        deepcopy(gh_auth.token),
    )
    try
        LibGit2.push(
            wrapper_repo;
            refspecs=["refs/heads/master"],
            remoteurl="https://github.com/$(deploy_repo).git",
            credentials=creds,
        )
    finally
        Base.shred!(creds)
    end
end